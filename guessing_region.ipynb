{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"avocado.csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags  type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0     1  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0     1  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0     1  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0     1  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0     1  2015  Albany  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_unique = df['type'].unique()\n",
    "type_unique_dict = {\"conventional\":1,\"organic\":2}\n",
    "df['type']=df[\"type\"].map(type_unique_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sklearn \n",
    "from sklearn import svm, preprocessing\n",
    "\n",
    "#see if there is any difference in accuray whther we include it or not(,\"Total Bags\",\"Large Bags\",\"XLarge Bags\",\"Total Volume\")\n",
    "# df=df.drop([\"Date\"],axis=1)\n",
    "\n",
    "df = sklearn.utils.shuffle(df)\n",
    "\n",
    "#try letting it guess the region was my original idea but now that i think about it doest make sense\n",
    "X=df.drop(\"region\",axis=1).values\n",
    "X=preprocessing.scale(X)\n",
    "y=df['region'].values\n",
    "\n",
    "test_size=500\n",
    "\n",
    "X_train=X[:-test_size]\n",
    "y_train=y[:-test_size]\n",
    "\n",
    "X_test=X[-test_size:]\n",
    "y_test=y[-test_size:]\n",
    "\n",
    "clf=svm.SVC()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [17749, 500]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5f5e4e0024e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [17749, 500]"
     ]
    }
   ],
   "source": [
    "clf.predict(X_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d134f17c2887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "X_test=X[-500:]\n",
    "y_test=y[-500:]\n",
    "for X,y in list(zip(X_test,y_test)):\n",
    "    if clf.predict([X])[0] == y:\n",
    "        print(1)\n",
    "        print(f\"Model: {clf.predict([X])[0]}, Actual:{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"NEW SECTION\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"avocado.csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags  type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0     1  2015       1  \n",
       "1     9505.56     9408.07       97.49          0.0     1  2015       1  \n",
       "2     8145.35     8042.21      103.14          0.0     1  2015       1  \n",
       "3     5811.16     5677.40      133.76          0.0     1  2015       1  \n",
       "4     6183.95     5986.26      197.69          0.0     1  2015       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type_unique = df['type'].unique()\n",
    "# type_unique_dict = {\"conventional\":1,\"organic\":2}\n",
    "# df['type']=df[\"type\"].map(type_unique_dict)\n",
    "# region_unique=df['region'].unique()\n",
    "# region_unique_dict = dict()\n",
    "# for i in range(len(region_unique)):\n",
    "#     region_unique_dict[region_unique[i]]=i+1\n",
    "# df['region']=df[\"region\"].map(region_unique_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn \n",
    "from sklearn import svm, preprocessing\n",
    "\n",
    "df = sklearn.utils.shuffle(df)\n",
    "\n",
    "X=df.drop([\"AveragePrice\",\"Date\"],axis=1).values\n",
    "X=preprocessing.scale(X)\n",
    "y=df['AveragePrice'].values\n",
    "\n",
    "test_size=500\n",
    "\n",
    "X_train=X[:-test_size]\n",
    "y_train=y[:-test_size]\n",
    "\n",
    "X_test=X[-test_size:]\n",
    "y_test=y[-test_size:]\n",
    "\n",
    "clf=svm.SVR(kernel=\"linear\")\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4131553666618918"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1.5997295591852967, Actual:1.4\n",
      "Model: 1.180170799208598, Actual:0.77\n",
      "Model: 1.1653874676443525, Actual:1.34\n",
      "Model: 1.5958182739453552, Actual:1.42\n",
      "Model: 1.6329861258353102, Actual:1.45\n",
      "Model: 1.2219328608622801, Actual:0.95\n",
      "Model: 1.630629925881224, Actual:1.7\n",
      "Model: 1.0032572846752175, Actual:1.2\n",
      "Model: 1.5967854210085632, Actual:1.63\n",
      "Model: 1.629864375188339, Actual:1.94\n",
      "Model: 1.6288845030325292, Actual:1.73\n",
      "Model: 1.5954834734601904, Actual:1.48\n",
      "Model: 1.0890370360430224, Actual:0.97\n",
      "Model: 1.59689524317926, Actual:1.88\n",
      "Model: 1.5961751754072617, Actual:1.4\n",
      "Model: 1.6476606807641496, Actual:1.23\n",
      "Model: 1.6287627586423785, Actual:1.19\n",
      "Model: 1.6619456976610991, Actual:2.15\n",
      "Model: 1.1761042731378395, Actual:0.99\n",
      "Model: 1.231592739435413, Actual:1.53\n",
      "Model: 1.1582604925488047, Actual:1.81\n",
      "Model: 1.188551913138383, Actual:1.38\n",
      "Model: 1.1635307520815825, Actual:1.15\n",
      "Model: 1.6299452380300292, Actual:1.68\n",
      "Model: 1.147814960585435, Actual:1.36\n",
      "Model: 1.201185760508963, Actual:1.05\n",
      "Model: 1.1391780042404847, Actual:1.16\n",
      "Model: 1.1242976105406488, Actual:1.24\n",
      "Model: 1.6965130961643187, Actual:1.75\n",
      "Model: 1.662164339834476, Actual:1.09\n",
      "Model: 1.1706826099294072, Actual:0.86\n",
      "Model: 1.1730652448217593, Actual:1.02\n",
      "Model: 1.1233355785548804, Actual:0.79\n",
      "Model: 1.4934112420826513, Actual:1.34\n",
      "Model: 1.1541811671462496, Actual:0.9\n",
      "Model: 1.1047177482979538, Actual:0.73\n",
      "Model: 1.152732483271747, Actual:1.42\n",
      "Model: 1.5959215796406179, Actual:2.0\n",
      "Model: 1.0864427719481258, Actual:1.05\n",
      "Model: 1.666096167780385, Actual:1.6\n",
      "Model: 1.1965976384068129, Actual:0.8\n",
      "Model: 1.597335158128415, Actual:1.68\n",
      "Model: 1.628305582476819, Actual:1.24\n",
      "Model: 1.1199383320112641, Actual:1.54\n",
      "Model: 1.1205956638191767, Actual:1.01\n",
      "Model: 1.628701490590255, Actual:1.97\n",
      "Model: 1.0253819981050059, Actual:0.94\n",
      "Model: 1.6323312680223103, Actual:1.29\n",
      "Model: 1.5960067758586312, Actual:1.73\n",
      "Model: 1.599048351221815, Actual:2.09\n",
      "Model: 1.1739513700844164, Actual:1.27\n",
      "Model: 1.1016314135233172, Actual:0.78\n",
      "Model: 1.6279591920179441, Actual:1.55\n",
      "Model: 1.6279491133374604, Actual:2.16\n",
      "Model: 1.1891007461914016, Actual:0.96\n",
      "Model: 1.1066311957796926, Actual:0.99\n",
      "Model: 1.1859216385214992, Actual:1.13\n",
      "Model: 1.688916888320228, Actual:1.54\n",
      "Model: 1.3861742099955188, Actual:1.4\n",
      "Model: 1.6258730399656658, Actual:1.31\n",
      "Model: 1.6606880447893204, Actual:1.52\n",
      "Model: 1.5977874799157734, Actual:1.59\n",
      "Model: 1.6596789397471055, Actual:0.94\n",
      "Model: 1.1213347444038917, Actual:1.03\n",
      "Model: 1.6558757050298012, Actual:1.25\n",
      "Model: 1.5964084303113246, Actual:1.45\n",
      "Model: 1.1199811131886404, Actual:1.14\n",
      "Model: 1.146216568364308, Actual:1.42\n",
      "Model: 1.1418152610634893, Actual:1.28\n",
      "Model: 1.0917803092281937, Actual:1.03\n",
      "Model: 1.1708690643815918, Actual:1.14\n",
      "Model: 1.116209244552045, Actual:1.14\n",
      "Model: 1.1085622011714826, Actual:0.93\n",
      "Model: 1.1300979415666768, Actual:0.8\n",
      "Model: 1.1676031397885578, Actual:1.5\n",
      "Model: 1.1549959946218027, Actual:1.93\n",
      "Model: 1.5968248483326264, Actual:1.69\n",
      "Model: 1.1092570478660977, Actual:0.99\n",
      "Model: 1.1626008460896937, Actual:0.83\n",
      "Model: 1.596664665468615, Actual:1.53\n",
      "Model: 1.596447453229481, Actual:1.84\n",
      "Model: 1.1387113475010617, Actual:1.16\n",
      "Model: 1.0899851827228315, Actual:1.22\n",
      "Model: 1.5972045552877423, Actual:2.01\n",
      "Model: 1.1297455571024397, Actual:1.0\n",
      "Model: 1.6287143167024045, Actual:2.08\n",
      "Model: 1.1438148487857258, Actual:1.25\n",
      "Model: 1.144524231259669, Actual:1.18\n",
      "Model: 1.6278607993947034, Actual:1.35\n",
      "Model: 1.1375618942796408, Actual:1.11\n",
      "Model: 1.6508321017754777, Actual:1.16\n",
      "Model: 1.5385882902598418, Actual:1.25\n",
      "Model: 1.1597061526093688, Actual:1.74\n",
      "Model: 1.176362320941995, Actual:1.49\n",
      "Model: 1.1731007721394702, Actual:1.32\n",
      "Model: 1.6287441094245951, Actual:1.77\n",
      "Model: 1.1074175889909343, Actual:1.04\n",
      "Model: 1.1736000926238144, Actual:1.08\n",
      "Model: 1.23019643147365, Actual:1.52\n",
      "Model: 1.1509357137968195, Actual:1.57\n",
      "Model: 1.5981472531201657, Actual:1.88\n",
      "Model: 1.6595192409321795, Actual:1.09\n",
      "Model: 1.2146221631951697, Actual:1.74\n",
      "Model: 1.5977234991454656, Actual:1.92\n",
      "Model: 1.1892735005082034, Actual:1.47\n",
      "Model: 1.1707085942886986, Actual:1.36\n",
      "Model: 1.6310303099649148, Actual:1.5\n",
      "Model: 1.6296724645563059, Actual:1.63\n",
      "Model: 1.1767879063422926, Actual:1.48\n",
      "Model: 1.1774205806257378, Actual:1.08\n",
      "Model: 1.1872398457648272, Actual:1.36\n",
      "Model: 0.42228587200262924, Actual:0.9\n",
      "Model: 1.6932999308020653, Actual:1.75\n",
      "Model: 1.5958796635691206, Actual:1.84\n",
      "Model: 1.0653571645987694, Actual:1.0\n",
      "Model: 1.5969711495564223, Actual:1.82\n",
      "Model: 0.9433844670107063, Actual:1.14\n",
      "Model: 1.6304510807671586, Actual:1.89\n",
      "Model: 1.1773424952001157, Actual:1.09\n",
      "Model: 1.1260954025614651, Actual:1.2\n",
      "Model: 1.6270667146494195, Actual:1.27\n",
      "Model: 1.1297516025631964, Actual:1.22\n",
      "Model: 1.6369584264622097, Actual:1.51\n",
      "Model: 1.6289255033086631, Actual:1.19\n",
      "Model: 1.6292766324769354, Actual:1.6\n",
      "Model: 1.1866856808211539, Actual:1.71\n",
      "Model: 1.6654069788642112, Actual:1.65\n",
      "Model: 1.6230976486182604, Actual:0.77\n",
      "Model: 1.6287721415213066, Actual:1.44\n",
      "Model: 1.689570322220182, Actual:1.59\n",
      "Model: 1.5969438104020233, Actual:1.61\n",
      "Model: 1.5990392131512505, Actual:1.92\n",
      "Model: 1.6277090558491385, Actual:1.34\n",
      "Model: 1.6707819942088507, Actual:1.59\n",
      "Model: 1.1028012184798435, Actual:0.85\n",
      "Model: 1.597809481351528, Actual:1.66\n",
      "Model: 1.6613758845330049, Actual:2.09\n",
      "Model: 1.1166002741524625, Actual:0.83\n",
      "Model: 0.8897200131503273, Actual:0.83\n",
      "Model: 1.628659047058606, Actual:2.05\n",
      "Model: 1.5969627597824412, Actual:2.11\n",
      "Model: 1.6287576872826801, Actual:1.04\n",
      "Model: 1.6285964924965937, Actual:2.19\n",
      "Model: 1.6599183038776333, Actual:1.88\n",
      "Model: 1.6595006649061146, Actual:2.43\n",
      "Model: 1.3618282655835814, Actual:1.16\n",
      "Model: 1.1799986382327698, Actual:1.59\n",
      "Model: 1.6686635918480464, Actual:1.91\n",
      "Model: 1.2200884117469175, Actual:1.41\n",
      "Model: 1.6651419716081546, Actual:1.71\n",
      "Model: 1.6609234676750066, Actual:1.88\n",
      "Model: 1.6293371428252859, Actual:2.16\n",
      "Model: 1.660660594060789, Actual:1.69\n",
      "Model: 1.0540804976393532, Actual:0.75\n",
      "Model: 1.181054357749134, Actual:1.42\n",
      "Model: 1.095417964194993, Actual:1.23\n",
      "Model: 1.1567251528928095, Actual:1.42\n",
      "Model: 1.1697844041259322, Actual:1.17\n",
      "Model: 1.116944248203332, Actual:0.82\n",
      "Model: 1.5963534649674944, Actual:1.68\n",
      "Model: 1.6928586039627773, Actual:1.69\n",
      "Model: 1.5959947139770327, Actual:2.09\n",
      "Model: 1.628724198316938, Actual:1.72\n",
      "Model: 1.6601696247303535, Actual:2.2\n",
      "Model: 1.6927476305036953, Actual:1.41\n",
      "Model: 0.9988239006896609, Actual:1.01\n",
      "Model: 1.1306973210466122, Actual:0.81\n",
      "Model: 1.1506445378075205, Actual:1.54\n",
      "Model: 1.140176820515733, Actual:1.55\n",
      "Model: 1.145352088338123, Actual:1.02\n",
      "Model: 1.33874984650201, Actual:1.37\n",
      "Model: 1.6594538686570988, Actual:1.81\n",
      "Model: 1.1617783915352486, Actual:0.99\n",
      "Model: 1.628329257789633, Actual:2.3\n",
      "Model: 1.5928911828225516, Actual:1.34\n",
      "Model: 1.6924799538564135, Actual:1.73\n",
      "Model: 1.1866516175667918, Actual:0.96\n",
      "Model: 1.2301566927173557, Actual:0.95\n",
      "Model: 1.1655241163092278, Actual:1.17\n",
      "Model: 1.1267937594815411, Actual:1.15\n",
      "Model: 1.627083881411519, Actual:1.06\n",
      "Model: 1.1459829253775435, Actual:1.07\n",
      "Model: 1.143690622379327, Actual:1.15\n",
      "Model: 1.6604285978071658, Actual:1.74\n",
      "Model: 1.5967346880261992, Actual:1.42\n",
      "Model: 1.6284166548647605, Actual:1.72\n",
      "Model: 1.6639392820082253, Actual:1.77\n",
      "Model: 0.9919042338192141, Actual:0.89\n",
      "Model: 1.595841591319076, Actual:1.97\n",
      "Model: 1.207344405052662, Actual:0.87\n",
      "Model: 1.1059316454595187, Actual:1.24\n",
      "Model: 1.6296023786495897, Actual:2.01\n",
      "Model: 1.1528414463379741, Actual:1.15\n",
      "Model: 1.1189969439044702, Actual:0.87\n",
      "Model: 0.9928558914073655, Actual:1.06\n",
      "Model: 1.1258866025161491, Actual:0.95\n",
      "Model: 1.628751326008782, Actual:1.44\n",
      "Model: 1.1601193040530648, Actual:0.94\n",
      "Model: 1.6280960212111109, Actual:1.75\n",
      "Model: 1.6602758623511398, Actual:1.51\n",
      "Model: 1.09231658239431, Actual:0.99\n",
      "Model: 1.59645162541251, Actual:1.85\n",
      "Model: 1.5968178424984127, Actual:1.57\n",
      "Model: 1.1202966423230538, Actual:1.17\n",
      "Model: 0.9488364977300219, Actual:0.93\n",
      "Model: 1.6277067250834274, Actual:1.42\n",
      "Model: 1.1439747145785801, Actual:1.41\n",
      "Model: 1.5974325635680935, Actual:2.3\n",
      "Model: 1.6613780328172472, Actual:1.79\n",
      "Model: 1.6931056718526851, Actual:1.51\n",
      "Model: 1.6618560522377233, Actual:1.87\n",
      "Model: 1.1091363088692476, Actual:1.0\n",
      "Model: 1.6292514937923877, Actual:1.42\n",
      "Model: 1.6277027905053632, Actual:1.46\n",
      "Model: 1.6287322948193288, Actual:2.01\n",
      "Model: 1.0377557834490114, Actual:1.34\n",
      "Model: 1.5978907633102062, Actual:2.09\n",
      "Model: 1.6048647303604944, Actual:1.22\n",
      "Model: 1.6606201080965284, Actual:1.46\n",
      "Model: 1.5955800550609944, Actual:1.58\n",
      "Model: 1.6315992298610036, Actual:1.94\n",
      "Model: 1.178763740796696, Actual:1.05\n",
      "Model: 1.1467421523720875, Actual:1.26\n",
      "Model: 1.1913535616555642, Actual:1.12\n",
      "Model: 1.076409419430493, Actual:0.56\n",
      "Model: 1.6930409955706494, Actual:1.91\n",
      "Model: 1.627327268233187, Actual:1.83\n",
      "Model: 1.1326713382593558, Actual:1.12\n",
      "Model: 1.2235899331537365, Actual:1.6\n",
      "Model: 1.6913047265987804, Actual:1.3\n",
      "Model: 1.173892145907903, Actual:1.13\n",
      "Model: 1.1449802563315057, Actual:1.1\n",
      "Model: 1.0983562140754952, Actual:0.67\n",
      "Model: 1.661104758095326, Actual:1.71\n",
      "Model: 1.5959337420224724, Actual:1.39\n",
      "Model: 1.1760651794692787, Actual:1.41\n",
      "Model: 1.5953506001302182, Actual:1.55\n",
      "Model: 1.5964240511785484, Actual:1.47\n",
      "Model: 1.2105826747999586, Actual:1.05\n",
      "Model: 1.5958714538782242, Actual:1.77\n",
      "Model: 1.2139836569056754, Actual:1.06\n",
      "Model: 1.6605516739731763, Actual:1.84\n",
      "Model: 1.5972784998840739, Actual:1.92\n",
      "Model: 1.6619461805832274, Actual:1.63\n",
      "Model: 1.10782048367185, Actual:1.2\n",
      "Model: 1.1127301003934593, Actual:1.19\n",
      "Model: 1.661892259487273, Actual:2.03\n",
      "Model: 1.0886146419180067, Actual:0.89\n",
      "Model: 1.1610546998108087, Actual:1.53\n",
      "Model: 1.6618281335794927, Actual:1.58\n",
      "Model: 1.6281053078497172, Actual:1.06\n",
      "Model: 1.5962450651148337, Actual:1.61\n",
      "Model: 1.6603570070587286, Actual:2.54\n",
      "Model: 1.6609312760589545, Actual:2.0\n",
      "Model: 1.1041679973720144, Actual:1.01\n",
      "Model: 1.0909658367978614, Actual:0.82\n",
      "Model: 1.1249090527406254, Actual:0.54\n",
      "Model: 1.663898009509542, Actual:1.68\n",
      "Model: 1.6363463317044469, Actual:1.84\n",
      "Model: 1.1777845031242498, Actual:0.83\n",
      "Model: 1.5970961304124163, Actual:1.65\n",
      "Model: 1.6280182141702542, Actual:1.61\n",
      "Model: 1.6296587244227916, Actual:1.51\n",
      "Model: 1.6608223527142505, Actual:1.37\n",
      "Model: 1.1085266383922043, Actual:1.15\n",
      "Model: 1.6297016514521339, Actual:1.87\n",
      "Model: 1.5972144152963144, Actual:1.11\n",
      "Model: 1.1770832446408899, Actual:1.45\n",
      "Model: 1.139394150633532, Actual:0.97\n",
      "Model: 1.6332305661842517, Actual:0.96\n",
      "Model: 1.5965177702180378, Actual:2.12\n",
      "Model: 1.6492845857118772, Actual:1.45\n",
      "Model: 1.5974568117684171, Actual:1.88\n",
      "Model: 1.6599711523652292, Actual:2.07\n",
      "Model: 1.2032046645785992, Actual:1.04\n",
      "Model: 1.6285112312324586, Actual:1.66\n",
      "Model: 1.0952863240764847, Actual:1.1\n",
      "Model: 1.1648139733024823, Actual:1.07\n",
      "Model: 1.1764749588318004, Actual:1.18\n",
      "Model: 1.1827910946382352, Actual:1.48\n",
      "Model: 1.1433793374506813, Actual:1.19\n",
      "Model: 1.1521464631143141, Actual:1.92\n",
      "Model: 1.234364223574444, Actual:1.01\n",
      "Model: 1.6629728358711424, Actual:2.44\n",
      "Model: 1.6607536419282363, Actual:1.44\n",
      "Model: 1.5968282215427125, Actual:1.63\n",
      "Model: 1.6280856667557562, Actual:1.81\n",
      "Model: 1.09978918339518, Actual:1.14\n",
      "Model: 1.5970006162483552, Actual:1.48\n",
      "Model: 1.162566844337926, Actual:1.47\n",
      "Model: 1.5948751185872434, Actual:1.22\n",
      "Model: 1.5974080841746867, Actual:2.27\n",
      "Model: 1.0151125557772707, Actual:0.85\n",
      "Model: 1.597432790662277, Actual:2.73\n",
      "Model: 1.6283033242192668, Actual:1.33\n",
      "Model: 1.1471829541172776, Actual:0.91\n",
      "Model: 1.6913504786613545, Actual:1.86\n",
      "Model: 1.6592265866332596, Actual:0.64\n",
      "Model: 1.1778009692075755, Actual:1.94\n",
      "Model: 1.6602675163519207, Actual:2.21\n",
      "Model: 1.6952636064516962, Actual:1.41\n",
      "Model: 1.3324498379679746, Actual:1.53\n",
      "Model: 1.2544846480132317, Actual:1.38\n",
      "Model: 1.5971515975372546, Actual:1.43\n",
      "Model: 1.1983348447081754, Actual:1.09\n",
      "Model: 0.9521393092562356, Actual:1.16\n",
      "Model: 1.1045113174263732, Actual:0.86\n",
      "Model: 1.6292430905610633, Actual:1.33\n",
      "Model: 1.5974183589401652, Actual:1.87\n",
      "Model: 1.1793976224901188, Actual:1.58\n",
      "Model: 1.701627070662143, Actual:1.75\n",
      "Model: 1.0207140148084035, Actual:0.92\n",
      "Model: 1.5978443202339967, Actual:1.54\n",
      "Model: 1.693292371504089, Actual:1.72\n",
      "Model: 1.5967758671348178, Actual:1.89\n",
      "Model: 1.6288179132567608, Actual:1.79\n",
      "Model: 1.1398295678891928, Actual:1.11\n",
      "Model: 1.3401919639249946, Actual:1.27\n",
      "Model: 1.6612741692847612, Actual:2.05\n",
      "Model: 1.5282882333264536, Actual:1.15\n",
      "Model: 1.1280986861682738, Actual:1.06\n",
      "Model: 1.2076753669455367, Actual:0.99\n",
      "Model: 1.1434596988070664, Actual:1.19\n",
      "Model: 1.1841567134095454, Actual:1.28\n",
      "Model: 1.6324187128621472, Actual:1.61\n",
      "Model: 1.052148817340855, Actual:0.61\n",
      "Model: 1.2072842046666774, Actual:1.58\n",
      "Model: 1.1597094989263605, Actual:1.0\n",
      "Model: 1.6086321057058282, Actual:1.0\n",
      "Model: 1.6291269024182162, Actual:1.48\n",
      "Model: 1.6624829524664162, Actual:1.85\n",
      "Model: 1.1162294856351567, Actual:1.18\n",
      "Model: 1.6270934865374382, Actual:0.86\n",
      "Model: 1.6618256225527945, Actual:2.1\n",
      "Model: 1.6605385427736175, Actual:1.9\n",
      "Model: 1.1382589492145065, Actual:1.26\n",
      "Model: 1.1353202665652036, Actual:0.8\n",
      "Model: 1.1824241158314295, Actual:1.47\n",
      "Model: 1.164682260721634, Actual:0.87\n",
      "Model: 1.0826178938165212, Actual:0.97\n",
      "Model: 0.9841490915994795, Actual:0.93\n",
      "Model: 1.6656287218196508, Actual:1.29\n",
      "Model: 1.0685688905841888, Actual:0.95\n",
      "Model: 1.5953026618539128, Actual:1.88\n",
      "Model: 1.5978822945370572, Actual:2.0\n",
      "Model: 1.6295381460279388, Actual:0.92\n",
      "Model: 1.6606384084326697, Actual:1.83\n",
      "Model: 1.5966705570348634, Actual:1.27\n",
      "Model: 1.0802880745946326, Actual:1.1\n",
      "Model: 1.6614209506939588, Actual:2.05\n",
      "Model: 1.5970330979695468, Actual:1.14\n",
      "Model: 1.0032333855542186, Actual:0.8\n",
      "Model: 1.6296080418721717, Actual:2.54\n",
      "Model: 1.6615038925479313, Actual:1.81\n",
      "Model: 1.1336815155027122, Actual:1.4\n",
      "Model: 1.1196683384311013, Actual:0.97\n",
      "Model: 1.3114343650402478, Actual:1.06\n",
      "Model: 1.5970753660730548, Actual:1.79\n",
      "Model: 1.6283378257100731, Actual:1.72\n",
      "Model: 1.1670278679512367, Actual:0.75\n",
      "Model: 1.2234160147281696, Actual:1.56\n",
      "Model: 1.660773020474935, Actual:2.22\n",
      "Model: 0.9189328137330492, Actual:0.93\n",
      "Model: 1.1380865183942352, Actual:1.0\n",
      "Model: 1.5965428733236142, Actual:1.82\n",
      "Model: 1.1532228509046543, Actual:1.37\n",
      "Model: 1.6924306194566705, Actual:1.68\n",
      "Model: 1.6619035685649952, Actual:2.13\n",
      "Model: 1.2311818001013903, Actual:1.08\n",
      "Model: 1.123598468981846, Actual:1.17\n",
      "Model: 1.1840312598194898, Actual:1.22\n",
      "Model: 0.9970964360499202, Actual:0.86\n",
      "Model: 1.1910712422815992, Actual:1.61\n",
      "Model: 1.5964983457083368, Actual:1.81\n",
      "Model: 1.0587494372867023, Actual:0.76\n",
      "Model: 0.9887574335460361, Actual:0.76\n",
      "Model: 1.5967661694135253, Actual:1.65\n",
      "Model: 1.1781946235598073, Actual:1.26\n",
      "Model: 1.6288420721876258, Actual:1.71\n",
      "Model: 1.5980333723313493, Actual:1.22\n",
      "Model: 1.1150611618838187, Actual:1.19\n",
      "Model: 1.6615168139244614, Actual:1.47\n",
      "Model: 1.210829839732465, Actual:1.26\n",
      "Model: 1.1675385778929228, Actual:1.3\n",
      "Model: 1.6299478281720556, Actual:1.73\n",
      "Model: 1.6594201632295096, Actual:1.18\n",
      "Model: 1.411029710098527, Actual:1.31\n",
      "Model: 1.6287637727142, Actual:1.27\n",
      "Model: 1.0912686559786096, Actual:1.28\n",
      "Model: 1.1462438724955994, Actual:1.61\n",
      "Model: 1.1052794733402163, Actual:0.82\n",
      "Model: 1.628023456166242, Actual:1.6\n",
      "Model: 1.1577559303799603, Actual:1.06\n",
      "Model: 1.4218488743600892, Actual:1.35\n",
      "Model: 1.596131255802475, Actual:1.32\n",
      "Model: 1.1537277972234252, Actual:1.47\n",
      "Model: 1.5900813332067956, Actual:1.65\n",
      "Model: 1.148024277068935, Actual:1.01\n",
      "Model: 1.661947438394358, Actual:2.82\n",
      "Model: 1.095664883647563, Actual:1.05\n",
      "Model: 1.6277450799519504, Actual:1.47\n",
      "Model: 1.1392267915829548, Actual:1.17\n",
      "Model: 1.692389567222276, Actual:1.54\n",
      "Model: 1.6291570287136978, Actual:0.97\n",
      "Model: 1.6619342052420711, Actual:1.81\n",
      "Model: 1.1595192526702869, Actual:1.12\n",
      "Model: 1.660900545875257, Actual:2.06\n",
      "Model: 1.1792353251720895, Actual:1.33\n",
      "Model: 1.6934496268041228, Actual:1.21\n",
      "Model: 1.5974375269232437, Actual:1.93\n",
      "Model: 1.127901246953883, Actual:1.26\n",
      "Model: 1.5981450761104476, Actual:1.5\n",
      "Model: 1.5958796884917907, Actual:2.0\n",
      "Model: 1.1542793438667966, Actual:1.42\n",
      "Model: 1.6308984621819613, Actual:1.71\n",
      "Model: 1.5925277693332216, Actual:1.27\n",
      "Model: 1.276421908098583, Actual:1.33\n",
      "Model: 1.1192151966928472, Actual:1.47\n",
      "Model: 1.180073413588858, Actual:1.08\n",
      "Model: 1.1239949534829154, Actual:1.2\n",
      "Model: 1.6928462058105735, Actual:1.36\n",
      "Model: 0.997177859904526, Actual:0.9\n",
      "Model: 0.8650392236863511, Actual:0.94\n",
      "Model: 1.250289410599899, Actual:1.31\n",
      "Model: 1.6305029645234421, Actual:2.31\n",
      "Model: 1.1328932753608016, Actual:1.22\n",
      "Model: 1.1351405702960777, Actual:0.88\n",
      "Model: 1.5959403151976095, Actual:1.32\n",
      "Model: 1.107336095660321, Actual:1.15\n",
      "Model: 1.6300462993930065, Actual:1.59\n",
      "Model: 1.6940141753969766, Actual:1.79\n",
      "Model: 1.1419810149685135, Actual:1.03\n",
      "Model: 1.596987954032369, Actual:1.53\n",
      "Model: 1.1277637724368952, Actual:1.27\n",
      "Model: 1.5976108361369805, Actual:1.72\n",
      "Model: 1.149287112801916, Actual:1.31\n",
      "Model: 1.6620338442114706, Actual:2.82\n",
      "Model: 1.0761287919058473, Actual:0.55\n",
      "Model: 1.59890375139181, Actual:1.64\n",
      "Model: 1.1073648714889757, Actual:1.12\n",
      "Model: 1.0741215656755392, Actual:0.82\n",
      "Model: 1.6293359856531309, Actual:1.46\n",
      "Model: 1.6287998105865955, Actual:1.38\n",
      "Model: 1.6931800337419636, Actual:2.05\n",
      "Model: 1.6293986600212436, Actual:1.4\n",
      "Model: 1.6914498158177511, Actual:1.69\n",
      "Model: 1.2132299354775742, Actual:1.21\n",
      "Model: 1.6278878543666506, Actual:0.89\n",
      "Model: 1.6540239629649198, Actual:1.85\n",
      "Model: 1.6592242714851784, Actual:1.08\n",
      "Model: 1.080841124453229, Actual:1.06\n",
      "Model: 1.5956332296008648, Actual:1.54\n",
      "Model: 0.7781363218449688, Actual:0.93\n",
      "Model: 1.628281919341625, Actual:1.26\n",
      "Model: 1.1378225450234682, Actual:0.79\n",
      "Model: 0.935882176420721, Actual:0.82\n",
      "Model: 1.5971529466822614, Actual:1.9\n",
      "Model: 1.629312374085742, Actual:1.8\n",
      "Model: 1.6596699792836542, Actual:1.7\n",
      "Model: 1.6605114375076262, Actual:1.4\n",
      "Model: 1.5979412674787707, Actual:1.86\n",
      "Model: 1.6618622773204148, Actual:1.78\n",
      "Model: 1.6615779053774498, Actual:1.85\n",
      "Model: 1.6326677879649205, Actual:2.01\n",
      "Model: 1.5977947831973847, Actual:1.56\n",
      "Model: 1.1905429499958016, Actual:1.27\n",
      "Model: 1.597263259698259, Actual:1.49\n",
      "Model: 1.596769874013559, Actual:1.48\n",
      "Model: 1.133357209162868, Actual:0.97\n",
      "Model: 1.6288685225753303, Actual:1.43\n",
      "Model: 1.6293970560746718, Actual:2.11\n",
      "Model: 1.1186109460754334, Actual:1.21\n",
      "Model: 1.596956689218452, Actual:0.99\n",
      "Model: 1.129052116990938, Actual:1.66\n",
      "Model: 1.11109323505932, Actual:1.07\n",
      "Model: 1.5970411055660476, Actual:1.37\n",
      "Model: 1.1181053847062994, Actual:0.91\n",
      "Model: 1.2129958944526393, Actual:1.14\n",
      "Model: 1.660448265830056, Actual:1.56\n",
      "Model: 1.1596444779098105, Actual:1.26\n",
      "Model: 1.121336683459492, Actual:0.91\n",
      "Model: 1.6614014562504005, Actual:1.15\n",
      "Model: 1.1759155499147003, Actual:1.6\n",
      "Model: 1.5956272142044576, Actual:1.81\n",
      "Model: 1.6607691593095089, Actual:2.07\n",
      "Model: 1.629438472863424, Actual:1.43\n",
      "Model: 1.6603036359726986, Actual:0.93\n",
      "Model: 1.1679134551436747, Actual:0.9\n",
      "Model: 1.6610117969249054, Actual:1.14\n",
      "Model: 1.6292184134423513, Actual:2.76\n",
      "Model: 1.1013346207914396, Actual:0.95\n",
      "Model: 1.6921492149519932, Actual:1.36\n",
      "Model: 1.120670553905537, Actual:1.02\n",
      "Model: 1.1246550043001002, Actual:1.56\n",
      "Model: 1.1878756528741774, Actual:1.59\n",
      "Model: 1.6599385894812175, Actual:1.86\n",
      "Model: 1.597708753004856, Actual:1.7\n",
      "Model: 1.210063348302659, Actual:1.0\n",
      "Model: 1.629010934033475, Actual:1.61\n",
      "Model: 1.2004223219461325, Actual:1.34\n"
     ]
    }
   ],
   "source": [
    "for X,y in list(zip(X_test,y_test)):\n",
    "    print(f\"Model: {clf.predict([X])[0]}, Actual:{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Albany'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-199c1a55e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Albany\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[0m\u001b[1;32m    466\u001b[0m                             order=\"C\", accept_large_sparse=False)\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Albany'"
     ]
    }
   ],
   "source": [
    "clf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
